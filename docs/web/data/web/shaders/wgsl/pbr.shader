{"spirv_code":[],"wgsl_code":"\nfn quantize_unorm(v: f32, n: u32) -> u32 {\n    let scale = f32((1 << n) - 1);\n    return u32(0.5 + (v * scale));\n}\nfn quantize_snorm(v: f32, n: u32) -> u32 {\n    let c = (1u << (n - 1u)) - 1u;\n    let scale = f32(c);\n    if v < 0. {\n        return (u32(-v * scale) & c) | (1u << (n - 1u));\n    } else {\n        return u32(v * scale) & c;\n    }\n}\n\nfn decode_unorm(i: u32, n: u32) -> f32 {    \n    let scale = f32((1 << n) - 1);\n    if (i == 0u) {\n        return 0.;\n    } else if (i == u32(scale)) {\n        return 1.;\n    } else {\n        return (f32(i) - 0.5) / scale;\n    }\n}\n\nfn decode_snorm(i: u32, n: u32) -> f32 {\n    let s = i >> (n - 1u);\n    let c = (1u << (n - 1u)) - 1u;\n    let scale = f32(c);\n    if s > 0u {\n        let r = f32(i & c) / scale;\n        return -r;\n    } else {\n        return f32(i & c) / scale;\n    }\n}\n\n\nfn decode_uv(v: u32) -> vec2<f32> {\n    return unpack2x16float(v);\n}\nfn decode_as_vec3(v: u32) -> vec3<f32> {\n    let vx = decode_unorm((v >> 20u) & 0x000003FFu, 10u);\n    let vy = decode_unorm((v >> 10u) & 0x000003FFu, 10u);\n    let vz = decode_unorm(v & 0x000003FFu, 10u);\n    return vec3<f32>(vx, vy, vz);\n}\n\nfn pack_normal(normal: vec3<f32>) -> vec2<f32> {\n    return vec2<f32>(normal.xy * 0.5 + 0.5);\n}\nfn unpack_normal(uv: vec2<f32>) -> vec3<f32> {\n    return vec3<f32>(uv.xy * 2. - 1., sqrt(1.-dot(uv.xy, uv.xy)));\n}\n\nfn pack_4_f32_to_unorm(value: vec4<f32>) -> u32 {\n    let r = quantize_unorm(value.x, 8u) << 24u;\n    let g = quantize_unorm(value.y, 8u) << 16u;\n    let b = quantize_unorm(value.z, 8u) << 8u;\n    let a = quantize_unorm(value.w, 8u);\n    return (r | g | b | a);\n}\nfn unpack_snorm_to_4_f32(v: u32) -> vec4<f32> {\n    let r = decode_snorm((v >> 24u) & 255u, 8u);\n    let g = decode_snorm((v >> 16u) & 255u, 8u);\n    let b = decode_snorm((v >> 8u) & 255u, 8u);\n    let a = decode_snorm(v & 255u, 8u);\n    return vec4<f32>(r,g,b,a);\n}\nfn unpack_unorm_to_4_f32(v: u32) -> vec4<f32> {\n    let r = decode_unorm((v >> 24u) & 255u, 8u);\n    let g = decode_unorm((v >> 16u) & 255u, 8u);\n    let b = decode_unorm((v >> 8u) & 255u, 8u);\n    let a = decode_unorm(v & 255u, 8u);\n    return vec4<f32>(r,g,b,a);\n}\n\n// 0-1 from 0-255\nfn linear_from_srgb(srgb: vec3<f32>) -> vec3<f32> {\n    let cutoff = srgb < vec3<f32>(10.31475);\n    let lower = srgb / vec3<f32>(3294.6);\n    let higher = pow((srgb + vec3<f32>(14.025)) / vec3<f32>(269.025), vec3<f32>(2.4));\n    return select(higher, lower, cutoff);\n}\n\n// [u8; 4] SRGB as u32 -> [r, g, b, a]\nfn unpack_color(color: u32) -> vec4<f32> {\n    return vec4<f32>(\n        f32(color & 255u),\n        f32((color >> 8u) & 255u),\n        f32((color >> 16u) & 255u),\n        f32((color >> 24u) & 255u),\n    );\n}\n\n// A single iteration of Bob Jenkins' One-At-A-Time hashing algorithm.\nfn hash( x: u32 ) -> u32 {\n    var v = x;\n    v += ( v << 10u );\n    v ^= ( v >>  6u );\n    v += ( v <<  3u );\n    v ^= ( v >> 11u );\n    v += ( v << 15u );\n    return v;\n}\n\n\nfn swap_f32(ptr_a: ptr<function, f32>, ptr_b: ptr<function, f32>) \n{\n    let c = *ptr_a;\n    *ptr_a = *ptr_b;\n    *ptr_b = c;\n}\nlet MAX_TEXTURE_ATLAS_COUNT: u32 = 8u;\nlet MAX_TEXTURE_COORDS_SET: u32 = 4u;\n\nlet TEXTURE_TYPE_BASE_COLOR: u32 = 0u;\nlet TEXTURE_TYPE_METALLIC_ROUGHNESS: u32 = 1u;\nlet TEXTURE_TYPE_NORMAL: u32 = 2u;\nlet TEXTURE_TYPE_EMISSIVE: u32 = 3u;\nlet TEXTURE_TYPE_OCCLUSION: u32 = 4u;\nlet TEXTURE_TYPE_SPECULAR_GLOSSINESS: u32 = 5u;\nlet TEXTURE_TYPE_DIFFUSE: u32 = 6u;\nlet TEXTURE_TYPE_EMPTY_FOR_PADDING: u32 = 7u;\nlet TEXTURE_TYPE_COUNT: u32 = 8u;\n\nlet MATERIAL_ALPHA_BLEND_OPAQUE = 0u;\nlet MATERIAL_ALPHA_BLEND_MASK = 1u;\nlet MATERIAL_ALPHA_BLEND_BLEND = 2u;\n\nlet MESH_FLAGS_NONE: u32 = 0u;\nlet MESH_FLAGS_VISIBLE: u32 = 1u;\nlet MESH_FLAGS_OPAQUE: u32 = 2u; // 1 << 1\nlet MESH_FLAGS_TRANSPARENT: u32 = 4u;  // 1 << 2\nlet MESH_FLAGS_WIREFRAME: u32 = 8u; // 1 << 3\nlet MESH_FLAGS_DEBUG: u32 = 16u; // 1 << 4\nlet MESH_FLAGS_UI: u32 = 32u; // 1 << 5\n\nlet CONSTANT_DATA_FLAGS_NONE: u32 = 0u;\nlet CONSTANT_DATA_FLAGS_SUPPORT_SRGB: u32 = 1u;\nlet CONSTANT_DATA_FLAGS_DISPLAY_MESHLETS: u32 = 2u;\nlet CONSTANT_DATA_FLAGS_DISPLAY_MESHLETS_SPHERE: u32 = 4u;\nlet CONSTANT_DATA_FLAGS_DISPLAY_MESHLETS_BOUNDING_BOX: u32 = 8u;\n\n\nstruct ConstantData {\n    view: mat4x4<f32>,\n    proj: mat4x4<f32>,\n    inverse_view_proj: mat4x4<f32>,\n    screen_width: f32,\n    screen_height: f32,\n    cam_fov: f32,\n    flags: u32,\n};\n\nstruct Vertex {\n    @location(0) position_and_color_offset: u32,\n    @location(1) normal_offset: i32,\n    @location(2) tangent_offset: i32,\n    @location(3) mesh_index: u32,\n    @location(4) uvs_offset: vec4<i32>,\n};\n\nstruct DrawCommand {\n    vertex_count: u32,\n    instance_count: u32,\n    base_vertex: u32,\n    base_instance: u32,\n};\n\nstruct DrawIndexedCommand {\n    vertex_count: u32,\n    instance_count: u32,\n    base_index: u32,\n    vertex_offset: i32,\n    base_instance: u32,\n};\n\nstruct Mesh {\n    vertex_offset: u32,\n    indices_offset: u32,\n    material_index: i32,\n    bhv_index: u32,\n    position: vec3<f32>,\n    meshlets_offset: u32,\n    scale: vec3<f32>,\n    meshlets_count: u32,\n    orientation: vec4<f32>,\n};\n\nstruct ConeCulling {\n    center: vec3<f32>,\n    cone_axis_cutoff: u32,\n};\n\nstruct Meshlet {\n    @location(5) mesh_index: u32,\n    @location(6) indices_offset: u32,\n    @location(7) indices_count: u32,\n    @location(8) bhv_index: u32,\n};\n\nstruct BHVNode {\n    min: vec3<f32>,\n    miss: i32,\n    max: vec3<f32>,\n    reference: i32, //-1 or mesh_index or meshlet_index or triangle_index\n};\n\n\nstruct LightData {\n    position: vec3<f32>,\n    light_type: u32,\n    color: vec4<f32>,\n    intensity: f32,\n    range: f32,\n    inner_cone_angle: f32,\n    outer_cone_angle: f32,\n};\n\nstruct TextureData {\n    texture_index: u32,\n    layer_index: u32,\n    total_width: f32,\n    total_height: f32,\n    area: vec4<f32>,\n};\n\nstruct Material {\n    textures_indices: array<i32, 8>,//TEXTURE_TYPE_COUNT>,\n    textures_coord_set: array<u32, 8>,//TEXTURE_TYPE_COUNT>,\n    roughness_factor: f32,\n    metallic_factor: f32,\n    alpha_cutoff: f32,\n    alpha_mode: u32,\n    base_color: vec4<f32>,\n    emissive_color: vec3<f32>,\n    occlusion_strength: f32,\n    diffuse_color: vec4<f32>,\n    specular_color: vec4<f32>,\n};\n\n\nstruct Lights {\n    data: array<LightData>,\n};\n\nstruct Textures {\n    data: array<TextureData>,\n};\n\nstruct Materials {\n    data: array<Material>,\n};\n\nstruct DrawCommands {\n    data: array<DrawCommand>,\n};\n\nstruct DrawIndexedCommands {\n    data: array<DrawIndexedCommand>,\n};\n\nstruct Meshes {\n    data: array<Mesh>,\n};\n\nstruct Meshlets {\n    data: array<Meshlet>,\n};\n\nstruct Indices {\n    data: array<u32>,\n};\n\nstruct Vertices {\n    data: array<Vertex>,\n};\n\nstruct Matrices {\n    data: array<mat4x4<f32>>,\n};\n\nstruct Positions {\n    data: array<u32>,\n};\n\nstruct Colors {\n    data: array<u32>,\n};\n\nstruct Normals {\n    data: array<u32>,\n};\n\nstruct Tangents {\n    data: array<vec4<f32>>,\n};\n\nstruct UVs {\n    data: array<u32>,\n};\n\nstruct MeshletsCulling {\n    data: array<ConeCulling>,\n};\n\nstruct BHV {\n    data: array<BHVNode>,\n};\n\nstruct MeshFlags {\n    data: array<u32>,\n};\n\n\nstruct VertexOutput {\n    @builtin(position) clip_position: vec4<f32>,\n    @location(0) uv: vec2<f32>,\n};\n\nstruct FragmentOutput {\n    @location(0) color: vec4<f32>,\n};\n\n\n@group(0) @binding(0)\nvar<uniform> constant_data: ConstantData;\n@group(0) @binding(1)\nvar<storage, read> meshes: Meshes;\n@group(0) @binding(2)\nvar<storage, read> meshlets: Meshlets;\n@group(0) @binding(3)\nvar<storage, read> materials: Materials;\n@group(0) @binding(4)\nvar<storage, read> textures: Textures;\n@group(0) @binding(5)\nvar<storage, read> lights: Lights;\n\n@group(1) @binding(0)\nvar gbuffer_1_texture: texture_2d<f32>;\n@group(1) @binding(1)\nvar gbuffer_2_texture: texture_2d<f32>;\n@group(1) @binding(2)\nvar gbuffer_3_texture: texture_2d<f32>;\n@group(1) @binding(3)\nvar gbuffer_4_texture: texture_2d<f32>;\n@group(1) @binding(4)\nvar gbuffer_5_texture: texture_2d<f32>;\n@group(1) @binding(5)\nvar gbuffer_6_texture: texture_2d<f32>;\n@group(1) @binding(6)\nvar gbuffer_7_texture: texture_2d<f32>;\n@group(1) @binding(7)\nvar depth_texture: texture_depth_2d;\n\n@group(2) @binding(0)\nvar default_sampler: sampler;\n\n@group(2) @binding(1)\nvar texture_1: texture_2d_array<f32>;\n@group(2) @binding(2)\nvar texture_2: texture_2d_array<f32>;\n@group(2) @binding(3)\nvar texture_3: texture_2d_array<f32>;\n@group(2) @binding(4)\nvar texture_4: texture_2d_array<f32>;\n@group(2) @binding(5)\nvar texture_5: texture_2d_array<f32>;\n@group(2) @binding(6)\nvar texture_6: texture_2d_array<f32>;\n@group(2) @binding(7)\nvar texture_7: texture_2d_array<f32>;\n\n\nfn sample_texture(tex_coords_and_texture_index: vec3<f32>) -> vec4<f32> {\n    let texture_data_index = i32(tex_coords_and_texture_index.z);\n    var v = vec4<f32>(0.);\n    var tex_coords = vec3<f32>(0.0, 0.0, 0.0);\n    if (texture_data_index < 0) {\n        return v;\n    }\n    let texture = &textures.data[texture_data_index];\n    let atlas_index = (*texture).texture_index;\n    let layer_index = i32((*texture).layer_index);\n\n    tex_coords.x = ((*texture).area.x + tex_coords_and_texture_index.x * (*texture).area.z) / (*texture).total_width;\n    tex_coords.y = ((*texture).area.y + tex_coords_and_texture_index.y * (*texture).area.w) / (*texture).total_height;\n    tex_coords.z = f32(layer_index);\n\n    switch (atlas_index) {\n        case 0u: { v = textureSampleLevel(texture_1, default_sampler, tex_coords.xy, layer_index, 0.); }\n        case 1u: { v = textureSampleLevel(texture_2, default_sampler, tex_coords.xy, layer_index, 0.); }\n        case 2u: { v = textureSampleLevel(texture_3, default_sampler, tex_coords.xy, layer_index, 0.); }\n        case 3u: { v = textureSampleLevel(texture_4, default_sampler, tex_coords.xy, layer_index, 0.); }\n        case 4u: { v = textureSampleLevel(texture_5, default_sampler, tex_coords.xy, layer_index, 0.); }\n        case 5u: { v = textureSampleLevel(texture_6, default_sampler, tex_coords.xy, layer_index, 0.); }\n        case 6u: { v = textureSampleLevel(texture_7, default_sampler, tex_coords.xy, layer_index, 0.); }\n        default { v = textureSampleLevel(texture_1, default_sampler, tex_coords.xy, layer_index, 0.); }\n    };\n    return v;\n}\nfn has_texture(material_index: u32, texture_type: u32) -> bool {\n    if (materials.data[material_index].textures_indices[texture_type] >= 0) {\n        return true;\n    }\n    return false;\n}\n\nfn material_texture_index(material_index: u32, texture_type: u32) -> i32 {\n    let material = &materials.data[material_index];\n    let texture_index = (*material).textures_indices[texture_type];\n    if (texture_index < 0) {\n        return 0;\n    }\n    return texture_index;\n}\n\nfn material_texture_coord_set(material_index: u32, texture_type: u32) -> u32 {\n    let material = &materials.data[material_index];\n    return (*material).textures_coord_set[texture_type];\n}\n\nfn get_uv(uv_set: vec4<u32>, texture_index: u32, coords_set: u32) -> vec3<f32> {\n    var uv = vec2<f32>(0., 0.);\n    switch (coords_set) {\n        case 1u: { uv = unpack2x16float(uv_set.y); }\n        case 2u: { uv = unpack2x16float(uv_set.z); }\n        case 3u: { uv = unpack2x16float(uv_set.w); }\n        default { uv = unpack2x16float(uv_set.x); }\n    }\n    return vec3<f32>(uv, f32(texture_index));\n}\n\nfn compute_uvs(material_index: u32, texture_type: u32, uv_set: vec4<u32>) -> vec3<f32> {\n    let texture_id = material_texture_index(material_index, texture_type);\n    let coords_set = material_texture_coord_set(material_index, texture_type);  \n    let uv = get_uv(uv_set, u32(texture_id), coords_set);\n    return uv;\n}\n\nfn sample_material_texture(material_index: u32, texture_type: u32, uv_set: vec4<u32>) -> vec4<f32> {\n    let uv = compute_uvs(material_index, texture_type, uv_set);\n    return sample_texture(uv);\n}\n\nfn extract_scale(m: mat4x4<f32>) -> vec3<f32> \n{\n    let s = mat3x3<f32>(m[0].xyz, m[1].xyz, m[2].xyz);\n    let sx = length(s[0]);\n    let sy = length(s[1]);\n    let det = determinant(s);\n    var sz = length(s[2]);\n    if (det < 0.) \n    {\n        sz = -sz;\n    }\n    return vec3<f32>(sx, sy, sz);\n}\n\nfn matrix_row(m: mat4x4<f32>, row: u32) -> vec4<f32> \n{\n    if (row == 1u) {\n        return vec4<f32>(m[0].y, m[1].y, m[2].y, m[3].y);\n    } else if (row == 2u) {\n        return vec4<f32>(m[0].z, m[1].z, m[2].z, m[3].z);\n    } else if (row == 3u) {\n        return vec4<f32>(m[0].w, m[1].w, m[2].w, m[3].w);\n    } else {        \n        return vec4<f32>(m[0].x, m[1].x, m[2].x, m[3].x);\n    }\n}\n\nfn normalize_plane(plane: vec4<f32>) -> vec4<f32> \n{\n    return (plane / length(plane.xyz));\n}\n\nfn unproject(ncd_pos: vec2<f32>, depth: f32) -> vec3<f32> \n{    \n    var world_pos = constant_data.inverse_view_proj * vec4<f32>(ncd_pos, depth, 1. );\n    world_pos /= world_pos.w;\n    return world_pos.xyz;\n}\n\nfn rotate_vector(v: vec3<f32>, orientation: vec4<f32>) -> vec3<f32> \n{\n    return v + 2. * cross(orientation.xyz, cross(orientation.xyz, v) + orientation.w * v);\n}\n\nfn transform_vector(v: vec3<f32>, position: vec3<f32>, orientation: vec4<f32>, scale: vec3<f32>) -> vec3<f32> \n{\n    return rotate_vector(v, orientation) * scale + position;\n}\n// Originally taken from https://github.com/KhronosGroup/glTF-WebGL-PBR\n// Commit a94655275e5e4e8ae580b1d95ce678b74ab87426\n//\n// This fragment shader defines a reference implementation for Physically Based Shading of\n// a microfacet surface material defined by a glTF model.\n//\n// References:\n// [1] Real Shading in Unreal Engine 4\n//     http://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf\n// [2] Physically Based Shading at Disney\n//     http://blog.selfshadow.com/publications/s2012-shading-course/burley/s2012_pbs_disney_brdf_notes_v3.pdf\n// [3] README.md - Environment Maps\n//     https://github.com/KhronosGroup/glTF-WebGL-PBR/#environment-maps\n// [4] \"An Inexpensive BRDF Model for Physically based Rendering\" by Christophe Schlick\n//     https://www.cs.virginia.edu/~jdl/bib/appearance/analytic%20models/schlick94b.pdf\n\nlet PI: f32 = 3.141592653589793;\nlet AMBIENT_COLOR: vec3<f32> = vec3<f32>(0.75, 0.75, 0.75);\nlet AMBIENT_INTENSITY = 0.25;\nlet NULL_VEC4: vec4<f32> = vec4<f32>(0.0, 0.0, 0.0, 0.0);\nlet MIN_ROUGHNESS = 0.04;\n\n// Constant normal incidence Fresnel factor for all dielectrics.\nlet Fdielectric: vec3<f32> = vec3<f32>(0.04, 0.04, 0.04);\nlet Epsilon: f32 = 0.00001;\n\nfn compute_alpha(material_index: u32, vertex_color_alpha: f32) -> f32 {\n    let material = &materials.data[material_index];\n    // NOTE: the spec mandates to ignore any alpha value in 'OPAQUE' mode\n    var alpha = 1.;\n    if ((*material).alpha_mode == MATERIAL_ALPHA_BLEND_OPAQUE) {\n        alpha = 1.;\n    } else if ((*material).alpha_mode == MATERIAL_ALPHA_BLEND_MASK) {\n        if (alpha >= (*material).alpha_cutoff) {\n            // NOTE: If rendering as masked alpha and >= the cutoff, render as fully opaque\n            alpha = 1.;\n        } else {\n            // NOTE: output_color.a < material.alpha_cutoff should not is not rendered\n            // NOTE: This and any other discards mean that early-z testing cannot be done!\n            alpha = -1.;\n        }\n    } else if ((*material).alpha_mode == MATERIAL_ALPHA_BLEND_BLEND) {\n        alpha = min((*material).base_color.a, vertex_color_alpha);\n    }\n    return alpha;\n}\n\nfn compute_normal(material_id: u32, normal: vec3<f32>, position: vec3<f32>, uv_set: vec4<u32>) -> vec3<f32> {\n    let material = &materials.data[material_id];\n    var n = normal;\n    //if (has_texture(material_id, TEXTURE_TYPE_NORMAL)) {    \n    //    let uv = compute_uvs(material_id, TEXTURE_TYPE_NORMAL, uv_set);    \n    //    //// get edge vectors of the pixel triangle \n    //    let dp1 = dpdx( position ); \n    //    let dp2 = dpdy( position ); \n    //    let duv1 = dpdx( uv.xy ); \n    //    let duv2 = dpdy( uv.xy );   \n    //    // solve the linear system \n    //    let dp2perp = cross( dp2, n ); \n    //    let dp1perp = cross( n, dp1 ); \n    //    let tangent = dp2perp * duv1.x + dp1perp * duv2.x; \n    //    let bitangent = dp2perp * duv1.y + dp1perp * duv2.y;\n    //    let t = normalize(tangent);\n    //    let b = normalize(bitangent); \n    //    let tbn = mat3x3<f32>(t, b, n);\n    //    let tn = sample_texture(uv);\n    //    n = tbn * (2.0 * tn.rgb - vec3<f32>(1.));\n    //    n = normalize(n);\n    //}\n    return n;\n}\n\n// GGX/Towbridge-Reitz normal distribution function.\n// Uses Disney's reparametrization of alpha = roughness^2.\nfn ndfGGX(cosLh: f32, roughness: f32) -> f32\n{\n\tlet alpha   = roughness * roughness;\n\tlet alphaSq = alpha * alpha;\n\n\tlet denom = (cosLh * cosLh) * (alphaSq - 1.0) + 1.0;\n\treturn alphaSq / (PI * denom * denom);\n}\n\n// Single term for separable Schlick-GGX below.\nfn gaSchlickG1(cosTheta: f32, k: f32) -> f32\n{\n\treturn cosTheta / (cosTheta * (1.0 - k) + k);\n}\n\n// Schlick-GGX approximation of geometric attenuation function using Smith's method.\nfn gaSchlickGGX(cosLi: f32, cosLo: f32, roughness: f32) -> f32\n{\n\tlet r = roughness + 1.0;\n\tlet k = (r * r) / 8.0; // Epic suggests using this roughness remapping for analytic lights.\n\treturn gaSchlickG1(cosLi, k) * gaSchlickG1(cosLo, k);\n}\n\n// Shlick's approximation of the Fresnel factor.\nfn fresnelSchlick(F0: vec3<f32>, cosTheta: f32) -> vec3<f32>\n{\n\treturn F0 + (vec3(1.0) - F0) * pow(1.0 - cosTheta, 5.0);\n}\n\n// The following equation models the Fresnel reflectance term of the spec equation (aka F())\n// Implementation of fresnel from [4], Equation 15\nfn specular_reflection(reflectance0: vec3<f32>, reflectance90: vec3<f32>, VdotH: f32) -> vec3<f32> {\n    return reflectance0 + (reflectance90 - reflectance0) * pow(clamp(1.0 - VdotH, 0.0, 1.0), 5.0);\n}\n// This calculates the specular geometric attenuation (aka G()),\n// where rougher material will reflect less light back to the viewer.\n// This implementation is based on [1] Equation 4, and we adopt their modifications to\n// alphaRoughness as input as originally proposed in [2].\nfn geometric_occlusion(alpha_roughness: f32, NdotL: f32, NdotV: f32) -> f32 {\n    let attenuationL = 2.0 * NdotL / (NdotL + sqrt(alpha_roughness * alpha_roughness + (1.0 - alpha_roughness * alpha_roughness) * (NdotL * NdotL)));\n    let attenuationV = 2.0 * NdotV / (NdotV + sqrt(alpha_roughness * alpha_roughness + (1.0 - alpha_roughness * alpha_roughness) * (NdotV * NdotV)));\n    return attenuationL * attenuationV;\n}\n\n// The following equation(s) model the distribution of microfacet normals across the area being drawn (aka D())\n// Implementation from \"Average Irregularity Representation of a Roughened Surface for Ray Reflection\" by T. S. Trowbridge, and K. P. Reitz\n// Follows the distribution function recommended in the SIGGRAPH 2013 course notes from EPIC Games [1], Equation 3.\nfn microfacet_distribution(alpha_roughness: f32, NdotH: f32) -> f32 {\n    let roughnessSq = alpha_roughness * alpha_roughness;\n    let f = (NdotH * roughnessSq - NdotH) * NdotH + 1.0;\n    return roughnessSq / (PI * f * f);\n}\n\nfn compute_brdf(world_pos: vec3<f32>, normal: vec3<f32>, material_id: u32, color: vec4<f32>, uv_set: vec4<u32>) -> vec4<f32> {\n    let material = &materials.data[material_id];\n    var perceptual_roughness = (*material).roughness_factor;\n    var metallic = (*material).metallic_factor;\n    if (has_texture(material_id, TEXTURE_TYPE_METALLIC_ROUGHNESS)) {        \n        // Roughness is stored in the 'g' channel, metallic is stored in the 'b' channel.\n        // This layout intentionally reserves the 'r' channel for (optional) occlusion map data\n        let t = sample_material_texture(material_id, TEXTURE_TYPE_METALLIC_ROUGHNESS, uv_set);\n        perceptual_roughness = perceptual_roughness * t.g;\n        metallic = metallic * t.b;\n    }\n    perceptual_roughness = clamp(perceptual_roughness, MIN_ROUGHNESS, 1.0);\n    metallic = clamp(metallic, 0.0, 1.0);\n    // Roughness is authored as perceptual roughness; as is convention,\n    // convert to material roughness by squaring the perceptual roughness [2].\n    let alpha_roughness = perceptual_roughness * perceptual_roughness;\n\n    var ao = 1.0;\n    var occlusion_strength = 1.;\n    if (has_texture(material_id, TEXTURE_TYPE_OCCLUSION)) {\n        let t = sample_material_texture(material_id, TEXTURE_TYPE_OCCLUSION, uv_set);\n        ao = ao * t.r;\n        occlusion_strength = (*material).occlusion_strength;\n    }\n    var emissive_color = vec3<f32>(0.);\n    if (has_texture(material_id, TEXTURE_TYPE_EMISSIVE)) {\n        let t = sample_material_texture(material_id, TEXTURE_TYPE_EMISSIVE, uv_set);\n        emissive_color = t.rgb * (*material).emissive_color;\n    }\n\n    let f0 = vec3<f32>(0.04);\n    var diffuse_color = color.rgb * (vec3<f32>(1.) - f0);\n    diffuse_color = diffuse_color * (1. - metallic);\n    let specular_color = mix(f0, color.rgb, metallic);        \n\n    // Compute reflectance.\n    let reflectance = max(max(specular_color.r, specular_color.g), specular_color.b);\n\n    // For typical incident reflectance range (between 4% to 100%) set the grazing reflectance to 100% for typical fresnel effect.\n    // For very low reflectance range on highly diffuse objects (below 4%), incrementally reduce grazing reflecance to 0%.\n    let reflectance90 = clamp(reflectance * 25.0, 0.0, 1.0);\n    let specular_environmentR0 = specular_color.rgb;\n    let specular_environmentR90 = vec3<f32>(1., 1., 1.) * reflectance90;\n\n    let n = compute_normal(material_id, normal, world_pos, uv_set);     // normal at surface point\n    let view_pos = constant_data.view[3].xyz;\n    let v = normalize(view_pos-world_pos);                      // Vector from surface point to camera\n\n    let NdotV = clamp(abs(dot(n, v)), 0.0001, 1.0);\n    let reflection = reflect(-v, n);\n    \n    var ambient_color = color.rgb * AMBIENT_COLOR * AMBIENT_INTENSITY;\n    ambient_color = mix(ambient_color, ambient_color * ao, occlusion_strength);\n    var final_color = ambient_color + emissive_color;\n\n    let num_lights = arrayLength(&lights.data);\n    for (var i = 0u; i < num_lights; i++ ) {\n        let light = &lights.data[i];\n        if ((*light).light_type == 0u) {\n            break;\n        }\n\n        let dir = (*light).position - world_pos;\n        let d = length(dir);\n        let l = normalize(dir);                             // Vector from surface point to light\n        let h = normalize(l + v);                           // Half vector between both l and v\n\n        let linear_att = 0.5 * d;\n        let quad_att = 0.5 * d * d;\n        let light_intensity = (*light).intensity * 1. / (linear_att * quad_att);\n        let light_contrib = light_intensity * (max((*light).range - d, (*light).range) / (*light).range);\n        \n        let NdotL = clamp(dot(n, l), 0.0001, 1.0);\n        let NdotH = clamp(dot(n, h), 0.0, 1.0);\n        let LdotH = clamp(dot(l, h), 0.0, 1.0);\n        let VdotH = clamp(dot(v, h), 0.0, 1.0);\n        \n        // Calculate the shading terms for the microfacet specular shading model\n        let F = specular_reflection(specular_environmentR0, specular_environmentR90, VdotH);\n        let G = geometric_occlusion(alpha_roughness, NdotL, NdotV);\n        let D = microfacet_distribution(alpha_roughness, NdotH);\n\n        let diffuse_contrib = (1. - F) * diffuse_color / PI;\n        let spec_contrib = F * G * D / (4.0 * NdotL * NdotV);\n        var light_color = NdotL * (*light).color.rgb * (diffuse_contrib + spec_contrib);\n        \n        final_color = final_color + light_color * light_contrib;\n    }\n    \n    return vec4<f32>(final_color, color.a);\n}\n\n\n\n\nfn sample_gbuffer(i: u32, pixel_coords: vec2<i32>) -> vec4<f32> {\n    var v = vec4<f32>(0.);\n    switch (i) {\n        case 0u: { \n            v = textureLoad(gbuffer_1_texture, pixel_coords, 0); \n        }\n        case 1u: { \n            v = textureLoad(gbuffer_2_texture, pixel_coords, 0); \n        }\n        case 2u: { \n            v = textureLoad(gbuffer_3_texture, pixel_coords, 0); \n        }\n        case 3u: { \n            v = textureLoad(gbuffer_4_texture, pixel_coords, 0); \n        }\n        case 4u: { \n            v = textureLoad(gbuffer_5_texture, pixel_coords, 0); \n        }\n        case 5u: { \n            v = textureLoad(gbuffer_6_texture, pixel_coords, 0); \n        }\n        case 6u: { \n            v = textureLoad(gbuffer_7_texture, pixel_coords, 0); \n        }\n        default: { \n            v = vec4<f32>(textureLoad(depth_texture, pixel_coords, 0)); \n        }\n    }\n    return v;\n}\n\nfn compute_world_position_from_depth(pixel_coords: vec2<i32>, uv: vec2<f32>) -> vec3<f32> {\n    let z = sample_gbuffer(7u, pixel_coords).r;\n    let clip_position = vec4<f32>(uv * 2. - 1., z * 2. - 1., 1.);\n    let homogeneous = constant_data.inverse_view_proj * clip_position;\n    return homogeneous.xyz / homogeneous.w;\n}\n\n@vertex\nfn vs_main(@builtin(vertex_index) in_vertex_index: u32) -> VertexOutput {\n    //only one triangle, exceeding the viewport size\n    let uv = vec2<f32>(f32((in_vertex_index << 1u) & 2u), f32(in_vertex_index & 2u));\n    let pos = vec4<f32>(uv * vec2<f32>(2., -2.) + vec2<f32>(-1., 1.), 0., 1.);\n\n    var vertex_out: VertexOutput;\n    vertex_out.clip_position = pos;\n    vertex_out.uv = uv;\n    return vertex_out;\n}\n\n\n@fragment\nfn fs_main(v_in: VertexOutput) -> @location(0) vec4<f32> {\n    let d = vec2<f32>(textureDimensions(depth_texture));\n    let pixel_coords = vec2<i32>(i32(v_in.uv.x * d.x), i32(v_in.uv.y * d.y));\n    \n    let vertex_color = sample_gbuffer(0u, pixel_coords);\n    let meshlet_id = pack4x8unorm(sample_gbuffer(2u, pixel_coords));\n    if meshlet_id == 0u {\n        return vec4<f32>(0., 0., 0., 0.);\n    }\n\n    var color = vec4<f32>(0., 0., 0., 0.);\n    let display_meshlets = constant_data.flags & CONSTANT_DATA_FLAGS_DISPLAY_MESHLETS;\n    if (display_meshlets != 0u) {\n        let meshlet_color = hash(meshlet_id - 1u);\n        color = vec4<f32>(vec3<f32>(\n            f32(meshlet_color & 255u),\n            f32((meshlet_color >> 8u) & 255u),\n            f32((meshlet_color >> 16u) & 255u)\n        ) / 255., 1.);\n    } else {\n        let uv_0 = pack4x8unorm(sample_gbuffer(3u, pixel_coords));\n        let uv_1 = pack4x8unorm(sample_gbuffer(4u, pixel_coords));\n        let uv_2 = pack4x8unorm(sample_gbuffer(5u, pixel_coords));\n        let uv_3 = pack4x8unorm(sample_gbuffer(6u, pixel_coords));\n        let uv_set = vec4<u32>(uv_0, uv_1, uv_2, uv_3);\n\n        let mesh_id = meshlets.data[meshlet_id - 1u].mesh_index;\n        let mesh = &meshes.data[mesh_id];\n        let material_id = u32((*mesh).material_index);\n        let texture_color = sample_material_texture(material_id, TEXTURE_TYPE_BASE_COLOR, uv_set);\n\n        let alpha = compute_alpha(material_id, vertex_color.a);\n        if alpha < 0. {\n            discard;\n        }\n\n        color = vec4<f32>(vertex_color.rgb * texture_color.rgb, alpha);\n\n        let packed_normal = unpack2x16float(pack4x8unorm(sample_gbuffer(1u, pixel_coords)));\n        let n = unpack_normal(packed_normal);\n        let world_pos = compute_world_position_from_depth(pixel_coords, v_in.uv);\n        let normal = rotate_vector(n, (*mesh).orientation);\n        color = compute_brdf(world_pos, normal, material_id, color, uv_set);\n    }\n\n    return color;\n}\n"}